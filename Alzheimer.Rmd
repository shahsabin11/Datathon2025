---
title: "Alzheimer"
output:
  word_document: default
  html_document: default
date: "2025-05-07"
author: "Sabin, Idil, Giang"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

##Installing packages:

```{r}
install.packages("recipes")
install.packages("caret")
install.packages("randomForest")
install.packages("xgboost")
install.packages("ggrepel")
install.packages("ggalt")
```


```{r}
```


```{r}
install.packages("tidyverse")

```

```{r}
library(tidyverse)
```
```{r}
#Loading the dataset into the environment
Alzheimer <- read.csv("alzheimers_disease_data.csv")
Medicare_Statewise <- read.csv("Medicare_Statewise_Data.csv")
Alzheimer_Cost <- read.csv("Alzheimers_Costs_By_Payment_Source.csv")

```

```{r}
summary(Alzheimer)
glimpse(Alzheimer)
```


```{r}
# Removing unnecessary columns: #Don't remove diabetes/BMI it could be important for alzh,combine Cholesterol levels to find categories of high / risky/low cholesterol


Alzheimer1 <- Alzheimer %>% 
  select(-HeadInjury, -SystolicBP, -DiastolicBP)

```

```{r}


# Step 1: Create a combined cholesterol score
Alzheimer1$CholesterolScore <- with(Alzheimer1, 
  CholesterolTotal + CholesterolLDL + CholesterolHDL + CholesterolTriglycerides)

# Step 2: Categorize into 5 levels based on percentile ranges or fixed thresholds
# You can choose thresholds based on quantiles or medical guidance. Here’s one example using quantiles:

# Compute quintiles to use as cut points
quantiles <- quantile(Alzheimer1$CholesterolScore, probs = seq(0, 1, 0.2), na.rm = TRUE)

# Step 3: Create a categorical column based on those cutoffs
Alzheimer1$CholesterolLevel <- cut(
  Alzheimer1$CholesterolScore,
  breaks = quantiles,
  include.lowest = TRUE,
  labels = c("Low", "Mild", "Medium", "Risky", "High")
)

# Optional: View the distribution
table(Alzheimer1$CholesterolLevel)

```


```{r}
# Save the dataset as a CSV in the current working directory
write.csv(Alzheimer1, "Alzheimer.csv", row.names = FALSE)

```

```{r}
# Convert binary and categorical variables to factors
factor_cols <- c(
  "Gender", "Smoking", "FamilyHistoryAlzheimers", "CardiovascularDisease",
  "Diabetes", "Depression", "Hypertension", "MemoryComplaints",
  "BehavioralProblems", "Confusion", "Disorientation", "PersonalityChanges",
  "DifficultyCompletingTasks", "Forgetfulness", "Diagnosis",
  "EducationLevel", "Ethnicity", "CholesterolLevel"
)

# Apply conversion
Alzheimer1[factor_cols] <- lapply(Alzheimer1[factor_cols], factor)

```

```{r}
library(ggplot2)

# Loop through each categorical variable
for (col in factor_cols[factor_cols != "Diagnosis"]) {
  print(
    ggplot(Alzheimer1, aes_string(x = col, fill = "Diagnosis")) +
      geom_bar(position = "fill") +
      scale_y_continuous(labels = scales::percent) +
      labs(
        title = paste("Proportion of Alzheimer's Diagnosis by", col),
        x = col,
        y = "Proportion of Patients",
        fill = "Alzheimer's Diagnosis"
      ) +
      theme_minimal()
  )
}

```

```{r}
# List of categorical variables to test (excluding Diagnosis itself)
categorical_vars <- c(
  "Gender", "Smoking", "FamilyHistoryAlzheimers", "CardiovascularDisease",
  "Diabetes", "Depression", "Hypertension", "MemoryComplaints",
  "BehavioralProblems", "Confusion", "Disorientation", "PersonalityChanges",
  "DifficultyCompletingTasks", "Forgetfulness", "EducationLevel",
  "Ethnicity", "CholesterolLevel"
)

# Initialize result storage
chi_results <- data.frame(
  Variable = character(),
  Chi_Square = numeric(),
  P_Value = numeric(),
  stringsAsFactors = FALSE
)

# Perform Chi-squared test for each categorical variable vs Diagnosis
for (var in categorical_vars) {
  tbl <- table(Alzheimer1[[var]], Alzheimer1$Diagnosis)
  test <- chisq.test(tbl)
  
  chi_results <- rbind(chi_results, data.frame(
    Variable = var,
    Chi_Square = round(test$statistic, 4),
    P_Value = signif(test$p.value, 4)
  ))
}

# Sort by significance
chi_results <- chi_results[order(chi_results$P_Value), ]
print(chi_results)

```




```{r}
# Select continuous numeric variables
numeric_vars <- c(
  "Age", "BMI", "AlcoholConsumption", "PhysicalActivity", "DietQuality", "SleepQuality",
  "CholesterolTotal", "CholesterolLDL", "CholesterolHDL", "CholesterolTriglycerides",
  "MMSE", "FunctionalAssessment", "ADL"
)

# Create a results data frame
cor_results <- data.frame(
  Variable = character(),
  Correlation = numeric(),
  P_Value = numeric(),
  stringsAsFactors = FALSE
)

# Loop through each variable and compute Pearson correlation with Diagnosis
for (var in numeric_vars) {
  test <- cor.test(Alzheimer1[[var]], as.numeric(as.character(Alzheimer1$Diagnosis)), method = "pearson")
  cor_results <- rbind(cor_results, data.frame(
    Variable = var,
    Correlation = test$estimate,
    P_Value = test$p.value
  ))
}

# View results sorted by correlation magnitude
cor_results[order(abs(cor_results$Correlation), decreasing = TRUE), ]

```

```{r}
# Numerical variables to consider:

# Functional Assessment, ADL, MMSE, Sleep Quality

# Categorical variables to consider

# MemoryComplaints, BehavorialProblems, FamilyHistoryAlzheimers, Ethnicity, EducationLevel, CholestrolLevel

```


```{r}
# Buidling the logistic regression model:

# Loading libraries

library(recipes)
library(caret)
library(randomForest)

```




```{r}
# Selected features and target:

selected_vars <- c(
  "Diagnosis", "FunctionalAssessment", "ADL", "MMSE", "SleepQuality",
  "MemoryComplaints", "BehavioralProblems", "FamilyHistoryAlzheimers",
  "Ethnicity", "EducationLevel", "CholesterolLevel"
)

```

```{r}
# Model Dataset creation:

model_df <- Alzheimer1[, selected_vars]


```

```{r}
# Splitting the dataset into training and test set (80/20 distribution)

set.seed(2025)
trainIndex <- createDataPartition(model_df$Diagnosis, p = 0.8, list = FALSE)
train_data <- model_df[trainIndex, ]
test_data <- model_df[-trainIndex, ]


```

```{r}
# Setting up tune grid for mtry (randomly selecting variables at each split)
set.seed(2025)
tune_grid <- expand.grid(mtry = c(2, 3, 4, 5))

```

```{r}
# Performing Cross-Validation (CV):
set.seed(2025)
ctrl <- trainControl(method = "cv", number = 5)
```

```{r}
# Training the random forest with model tuning:
set.seed(2025)
rf_tuned <- train(
  Diagnosis ~ .,
  data = train_data,
  method = "rf",
  tuneGrid = tune_grid,
  ntree = 500,
  trControl = ctrl,
  importance = TRUE
)
```

```{r}
# Printing and plotting the model summary
set.seed(2025)
print(rf_tuned)
plot(rf_tuned)

```


```{r}
# Prediction on the test set:
set.seed(2025)
rf_predictions <- predict(rf_tuned, newdata = test_data)
```

```{r}
# Evaluating performance through Confusion matrix:
set.seed(2025)
conf_matrix <- confusionMatrix(rf_predictions, test_data$Diagnosis)
print(conf_matrix)

```

```{r}


# Extract variable importance
importance_rf <- varImp(rf_tuned)

# Print importance scores
print(importance_rf)

# Plot variable importance
plot(importance_rf, top = 15, main = "Random Forest Variable Importance")

```

```{r}

summary(Medicare_Statewise)
```
```{r}
# Renaming a few columns:
library(dplyr)

Medicare_Statewise <- Medicare_Statewise %>%
  rename(
    ED_Visits_per_1000_Ben = ED.Visits.per.1.000.Beneficiaries,
    Readmission_30_Days = Hospital.Readmission.within.30.Days....
  )

glimpse(Medicare_Statewise)


```
```{r}
# Converting ED_Visits into percentage:
library(dplyr)

# Normalize ED visits to percentage scale (0–100%)
Medicare_Statewise <- Medicare_Statewise %>%
  mutate(ED_Visits_Percent = 100 * (ED_Visits_per_1000_Ben - min(ED_Visits_per_1000_Ben)) / 
                                   (max(ED_Visits_per_1000_Ben) - min(ED_Visits_per_1000_Ben)))

```

```{r}
library(tidyr)

df_long <- Medicare_Statewise %>%
  select(State, ED_Visits_Percent, Readmission_30_Days) %>%
  pivot_longer(cols = c(ED_Visits_Percent, Readmission_30_Days),
               names_to = "Metric", values_to = "Value")

```



```{r}
library(ggplot2)
library(ggalt)  # for geom_dumbbell

# Creating dumbbell chart
df_dumbbell <- Medicare_Statewise %>%
  select(State, ED_Visits_Percent, Readmission_30_Days)

ggplot(df_dumbbell, aes(y = reorder(State, ED_Visits_Percent))) +
  geom_dumbbell(
    aes(x = Readmission_30_Days, xend = ED_Visits_Percent),
    color = "gray80", size = 1,
    colour_x = "orange", colour_xend = "steelblue"
  ) +
  labs(
    title = "Comparison of ED Visits and Readmission Rates by State",
    x = "Percentage",
    y = "State"
  ) +
  theme_minimal()

```






```{r}
# Renaming the column for Benficiaries with and without Alzheimer
Alzheimer_Cost <- Alzheimer_Cost %>%
  rename(
    `Beneficiaries with Alzheimer` = `Beneficiaries.with.Alzheimer.s.or.Other.Dementias`,
    `Beneficiaries without Alzheimer` = `Beneficiaries.without.Alzheimer.s.or.Other.Dementias`,
    `Payment Source` = `Payment.Source`
  )
```


```{r}
library(ggplot2)
library(tidyr)
library(dplyr)

# Convert from wide to long format
Alzheimer_Cost_long <- Alzheimer_Cost %>%
  pivot_longer(
    cols = c(`Beneficiaries with Alzheimer`, `Beneficiaries without Alzheimer`),
    names_to = "Group",
    values_to = "Cost"
  )

# Create grouped bar chart
ggplot(Alzheimer_Cost_long, aes(x = reorder(`Payment Source`, -Cost), y = Cost, fill = Group)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Cost Comparison by Payment Source for Alzheimer’s and Non-Alzheimer’s Beneficiaries",
    x = "Payment Source",
    y = "Cost (USD)",
    fill = "Group"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
